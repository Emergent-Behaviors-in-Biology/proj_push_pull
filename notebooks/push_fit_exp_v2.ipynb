{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '../py_scripts')\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import numpy.random as rand\n",
    "import numpy.linalg as la\n",
    "import numpy.ma as ma\n",
    "import scipy.optimize as opt\n",
    "import scipy.stats as stats\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "\n",
    "import push_pull as pp\n",
    "import noise_models as noise\n",
    "\n",
    "sns.set(context='talk', font_scale=1.0, color_codes=True, palette='deep', style='ticks', \n",
    "        rc={'mathtext.fontset': 'cm', 'xtick.direction': 'in','ytick.direction': 'in',\n",
    "            'axes.linewidth': 1.5, 'figure.dpi':100, 'text.usetex':False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# dataset, construct, model\n",
    "s_list = [\n",
    "#     ['I+E', 'I+E', 'push'],\n",
    "#     ['S+E', 'S+E', 'push'],\n",
    "    ['S+R', 'S+R', 'push'],\n",
    "#     ['RR(E) only', 'RR(E) only', 'push'],\n",
    "#     ['RR+A', 'RR+A', 'push'],\n",
    "#     ['Substrate only', 'Substrate only', 'background']\n",
    "         ]\n",
    "\n",
    "df_info = pd.DataFrame(s_list, columns=['dataset', 'construct', 'model'])\n",
    "     \n",
    "display(df_info)\n",
    "\n",
    "df_list = []\n",
    "for index, row in df_info.iterrows():\n",
    "    df = pd.read_csv(\"../data/push_data/{}.csv\".format(row['dataset']))    \n",
    "    df['dataset'] = row['dataset']    \n",
    "    df_list.append(df)\n",
    "    \n",
    "    \n",
    "df = pd.concat(df_list).drop(\"Unnamed: 0\", axis=1, errors='ignore')\n",
    "\n",
    "\n",
    "df.set_index(\"dataset\", inplace=True, append=True)\n",
    "df = df.reorder_levels(df.index.names[::-1])\n",
    "\n",
    "\n",
    "df = df[(df[df.columns[:-1]] > 0).all(axis=1)].rename(columns={'Kinase': 'WT_anti', 'Substrate': 'ST_anti', 'Phosphorylation': 'SpT_anti'})\n",
    "\n",
    "df['phospho_frac_anti'] = df['SpT_anti'] / df['ST_anti']\n",
    "\n",
    "\n",
    "print(len(df.index), \"/\", len(df.index))\n",
    "\n",
    "display(df)\n",
    "\n",
    "\n",
    "nconstructs = df.groupby(\"dataset\").ngroups\n",
    "fig, axes = plt.subplots(nconstructs, 1, figsize=(4, 4*nconstructs),\n",
    "                        sharex=True, sharey=True, squeeze=False)\n",
    "\n",
    "for i, (construct, group) in enumerate(df.groupby(\"dataset\")):\n",
    "    \n",
    "    sns.histplot(group, x='WT_anti', y='phospho_frac_anti', \n",
    "                 log_scale=(True, True), ax=axes[i, 0])\n",
    "    \n",
    "    axes[i, 0].hlines(1e0, xmin=1e0, xmax=1e5, color='k', linestyle='--')\n",
    "    axes[i, 0].set_title(construct)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbins_anti = 100\n",
    "nbins_GFP = 100\n",
    "\n",
    "nonempty_writer_noise = noise.EmpiricalNoise(\"../data/noise_data/Kinase Noise.csv\", \n",
    "                                   'Flag Antibody', 'GFP', \n",
    "                                   nbins_anti=nbins_anti, nbins_GFP=nbins_GFP, \n",
    "                                   verbose=True)\n",
    "\n",
    "empty_writer_noise = noise.EmpiricalNoise(\"../data/noise_data/Empty Cell.csv\", \n",
    "                                   'Flag Antibody', 'GFP', \n",
    "                                   nbins_anti=nbins_anti, nbins_GFP=nbins_GFP, \n",
    "                                   verbose=True)\n",
    "\n",
    "mix_writer_noise = noise.MixtureNoise(nonempty_writer_noise, empty_writer_noise)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(6, 4))\n",
    "nonempty_writer_noise.plot(ax)\n",
    "empty_writer_noise.plot(ax, color='g')\n",
    "plt.show()\n",
    "\n",
    "writer_noise = nonempty_writer_noise\n",
    "    \n",
    "substrate_noise = noise.EmpiricalNoise(\"../data/noise_data/Substrate Noise.csv\", \n",
    "                                   'Myc Antibody', 'GFP', \n",
    "                                   nbins_anti=nbins_anti, nbins_GFP=nbins_GFP, \n",
    "                                   verbose=True)\n",
    "\n",
    "empty_substrate_noise = noise.EmpiricalNoise(\"../data/noise_data/Empty Cell.csv\", \n",
    "                                   'Myc Antibody', 'GFP', \n",
    "                                   nbins_anti=nbins_anti, nbins_GFP=nbins_GFP, \n",
    "                                   verbose=True)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(6, 4))\n",
    "substrate_noise.plot(ax)\n",
    "empty_substrate_noise.plot(ax, color='g')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "    \n",
    "phospho_noise = noise.EmpiricalNoise(\"../data/noise_data/PE Noise.csv\", \n",
    "                                   'PE Antibody', 'GFP', \n",
    "                                   nbins_anti=nbins_anti, nbins_GFP=nbins_GFP, \n",
    "                                   verbose=True)\n",
    "\n",
    "empty_phospho_noise = noise.EmpiricalNoise(\"../data/noise_data/Empty Cell.csv\", \n",
    "                                   'Phosphorylation', 'GFP', \n",
    "                                   nbins_anti=nbins_anti, nbins_GFP=nbins_GFP, \n",
    "                                   verbose=True)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(6, 4))\n",
    "phospho_noise.plot(ax)\n",
    "empty_phospho_noise.plot(ax, color='g')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for dataset, group in df.groupby(\"dataset\"):\n",
    "    \n",
    "#     print(dataset)\n",
    "    \n",
    "    frac = mix_writer_noise.calc_mixture(group['WT_anti'])\n",
    "    \n",
    "    fig, ax = plt.subplots(1, 1, figsize=(6, 4))\n",
    "    \n",
    "    ax.hist(np.log10(group['WT_anti']), histtype='step', bins='auto', \n",
    "            label='full', density=True, color='r')\n",
    "    ax.hist(np.log10(mix_writer_noise.nonempty.df['Flag Antibody']), color='b', density=True,\n",
    "            histtype='step', bins='auto', label='nonempty')\n",
    "    ax.hist(np.log10(mix_writer_noise.empty.df['Flag Antibody']), color='g', density=True,\n",
    "            histtype='step', bins='auto', label='empty')\n",
    "    \n",
    "    ax.set_xlabel(\"anti\")\n",
    "    \n",
    "#     x = np.concatenate([writer_noise.nonempty.df['Flag Antibody'], \n",
    "#                         writer_noise.empty.df['Flag Antibody']])\n",
    "#     weights = np.concatenate([(1-frac)*np.ones_like(writer_noise.nonempty.df['Flag Antibody']),\n",
    "#                              frac*np.ones_like(writer_noise.empty.df['Flag Antibody'])])\n",
    "    \n",
    "    \n",
    "#     ax.hist(np.log10(x), weights=weights, color='m', density=True,\n",
    "#             histtype='step', bins=100, label='mixture')\n",
    "    \n",
    "    \n",
    "#     hist, bin_edges = np.histogram(np.log10(group['WT_anti']), bins='auto')\n",
    "    \n",
    "#     hist = hist/hist.sum()\n",
    "    \n",
    "#     ax.plot(10**((bin_edges[:-1]+bin_edges[1:])/2), hist, 'b', label='full')\n",
    "    \n",
    "#     x = writer_noise.nonempty.edges_anti\n",
    "#     ax.plot(10**((x[:-1]+x[1:])/2), writer_noise.nonempty.prob_anti, 'g', label='nonempty')\n",
    "#     x = writer_noise.empty.edges_anti\n",
    "#     ax.plot(10**((x[:-1]+x[1:])/2), writer_noise.empty.prob_anti, 'r', label='empty')\n",
    "    \n",
    "    \n",
    "    ax.set_xscale('log')\n",
    "    ax.legend(loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "        \n",
    "    df.loc[group.index, 'WT_GFP'] = writer_noise.anti_to_GFP(group['WT_anti'], plot=False)\n",
    "\n",
    "    df.loc[group.index, 'ST_GFP'] = substrate_noise.anti_to_GFP(group['ST_anti'], plot=False)\n",
    "\n",
    "    df.loc[group.index, 'SpT_GFP'] = phospho_noise.anti_to_GFP(group['SpT_anti'], plot=False)\n",
    "    \n",
    "    \n",
    "df['phospho_frac_GFP'] = df['SpT_GFP'] / df['ST_GFP']\n",
    "\n",
    "\n",
    "print(len(df))\n",
    "df.dropna(inplace=True)\n",
    "print(len(df))\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve(df, df_info, param_dict, x0, bounds, verbose=False):\n",
    "\n",
    "    if verbose:\n",
    "        start = time.time()\n",
    "\n",
    "    def func(x):\n",
    "                        \n",
    "        loss = 0.0\n",
    "        norm = 0.0\n",
    "        \n",
    "        for index, row in df_info.iterrows():\n",
    "            dataset = row['dataset']\n",
    "            \n",
    "            construct = row['construct']\n",
    "            \n",
    "            df_data = df.query(\"dataset=='{}'\".format(dataset))\n",
    "            \n",
    "            N_data = len(df_data.index)\n",
    "            \n",
    "            norm += N_data\n",
    "            \n",
    "            noise_params = np.array(x)[param_dict[construct][0:1]]\n",
    "            model_params = 10**np.array(x)[param_dict[construct][1:]]\n",
    "            \n",
    "#             print(noise_params, model_params)\n",
    "            \n",
    "            if row['model'] == 'background':\n",
    "                model = pp.Background()\n",
    "                \n",
    "                L = model.loss_log(df_data['SpT_GFP'].values, \n",
    "                                            df_data[['ST_GFP']].values,\n",
    "                                            model_params)\n",
    "                \n",
    "#                 print(L)\n",
    "                \n",
    "                loss += N_data * L\n",
    "                \n",
    "\n",
    "            elif row['model'] == 'push':\n",
    "                \n",
    "                \n",
    "                \n",
    "#                 print(noise_params)\n",
    "                \n",
    "                model = pp.PushAmp()\n",
    "                \n",
    "                L = N_data * model.loss_log(df_data['SpT_GFP'].values, \n",
    "                                            df_data[['WT_GFP', 'ST_GFP']].values,\n",
    "                                            model_params)\n",
    "\n",
    "#                 L = model.loss_mixture(df_data['SpT_GFP'].values, \n",
    "#                                             df_data[['WT_GFP', 'ST_GFP']].values,\n",
    "#                                             model_params, noise_params)\n",
    "\n",
    "                loss += N_data * L\n",
    "    \n",
    "#                 print(L)\n",
    "                \n",
    "            loss /= norm\n",
    "        \n",
    "#         print(loss)\n",
    "        return loss\n",
    "\n",
    "\n",
    "    if verbose:\n",
    "        print(\"Initial Loss:\", func(x0))\n",
    "\n",
    "\n",
    "    res = opt.minimize(func, x0, method='L-BFGS-B', \n",
    "                       jac='2-point', bounds=bounds, \n",
    "                       options={'iprint':101, 'eps': 1e-8, \n",
    "                                'gtol': 1e-8, 'ftol':1e-12,\n",
    "                               'finite_diff_rel_step': 1e-4})\n",
    "    \n",
    "\n",
    "    if verbose:\n",
    "        print(\"Final Loss:\", res.fun)\n",
    "\n",
    "        end = time.time()\n",
    "\n",
    "        print(\"Time Elapsed\", end-start, \"seconds\")\n",
    "\n",
    "        print(res)\n",
    "        \n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_count = {'push': 0, 'background': 0}\n",
    "param_dict = {}\n",
    "\n",
    "param_labels = [r\"$\\rho$\", r\"$\\log_{10}(v_{bg}^p)$\", r\"$\\log_{10}(v_{WS}^p)$\"]\n",
    "x0 = [0.0, 0.0, 1.0]\n",
    "bounds = [(0.0, 1.0e-6), (None, None), (None, None)]\n",
    "\n",
    "for index, row in df_info.iterrows():\n",
    "    \n",
    "    construct = row['construct']\n",
    "    model = row['model']\n",
    "                \n",
    "    if construct not in param_dict:\n",
    "        if model == 'background':\n",
    "            param_dict[construct] = [0, 1]\n",
    "            model_count['background'] +=1\n",
    "        elif model == 'push':\n",
    "            param_dict[construct] = [0, 1, 2, 3+model_count['push']]\n",
    "            model_count['push'] += 1\n",
    "            \n",
    "            param_labels.append(construct + \": \" + r\"$\\log_{10}(\\alpha_{WS})$\")\n",
    "            x0.append(3.0)\n",
    "            bounds.append((None, None))\n",
    "        \n",
    "\n",
    "print(param_labels)\n",
    "print(param_dict)\n",
    "print(model_count)\n",
    "\n",
    "print(x0)\n",
    "print(bounds)\n",
    "\n",
    "\n",
    "res = solve(df, df_info, param_dict, x0, bounds, verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hess = la.inv(res.hess_inv.todense())\n",
    "\n",
    "print(\"Model parameters:\")\n",
    "for i in range(len(res.x)):\n",
    "    display(Markdown(param_labels[i] + \" = \" + str(res.x[i])))\n",
    "    \n",
    "\n",
    "s_list = []\n",
    "\n",
    "for i, labeli in enumerate(param_labels):\n",
    "    for j, labelj in enumerate(param_labels):\n",
    "        s_list.append([labeli, labelj, np.log10(np.abs(hess[i, j])+1e-4)])\n",
    "\n",
    "df_hess = pd.DataFrame(s_list, columns=['param1', 'param2', 'hess'])\n",
    "\n",
    "sns.heatmap(df_hess.pivot(\"param1\", \"param2\", \"hess\"), \n",
    "            cbar_kws={'label': r\"$\\log_{10}(|H_{ij}|)$\"}, \n",
    "            cmap='cividis', center=0)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "evals, evecs = la.eigh(hess)\n",
    "\n",
    "evals = evals[::-1]\n",
    "evecs = evecs[:, ::-1]\n",
    "\n",
    "s_list = []\n",
    "for i, labeli in enumerate(param_labels):\n",
    "    for j in range(len(evals)):\n",
    "        s_list.append([labeli, \"{0:}: {1:07.4f}\".format(j, evals[j]), np.abs(evecs[i, j])])\n",
    "        \n",
    "\n",
    "df_evecs = pd.DataFrame(s_list, columns=['param', \"PC (eigenval)\", 'val'])\n",
    "\n",
    "sns.heatmap(df_evecs.pivot(\"PC (eigenval)\", \"param\", \"val\"), \n",
    "            cbar_kws={'label': \"weight\"}, \n",
    "            cmap='RdBu', center=0)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hess_inv = res.hess_inv.todense()\n",
    "\n",
    "zippers = {}\n",
    "\n",
    "\n",
    "for index, row in df_info.iterrows():\n",
    "\n",
    "    construct = row['construct']\n",
    "    if row['model'] == 'push':\n",
    "        \n",
    "        if construct not in zippers:\n",
    "            idx = param_dict[construct][3]\n",
    "            \n",
    "            zippers[construct] = (res.x[idx], 0.01*np.sqrt(hess_inv[idx, idx]))\n",
    "\n",
    "\n",
    "print(zippers)\n",
    "            \n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 6))\n",
    "\n",
    "y = 10**np.array([zippers[key][0] for key in zippers])\n",
    "y_low =  y - 10**np.array([zippers[key][0]-zippers[key][1] for key in zippers])\n",
    "y_up =  10**np.array([zippers[key][0]+zippers[key][1] for key in zippers]) - y\n",
    "\n",
    "ax.bar(zippers.keys(), y, yerr=(y_low, y_up))\n",
    "\n",
    "ax.set_yscale('log')\n",
    "ax.set_xlabel(\"Zipper\")\n",
    "ax.set_ylabel(\"Inverse Binding Strength\\n\" + r\"$\\alpha_{WS} = k^{off}/k^{on}$ [GFP]\")\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for index, row in df_info.iterrows():\n",
    "    \n",
    "    dataset = row['dataset']\n",
    "    model = row['model']\n",
    "    construct = row['construct']\n",
    "    \n",
    "    df_data = df_data = df.query(\"dataset=='{}'\".format(dataset))\n",
    "    \n",
    "    \n",
    "    if model == 'push':\n",
    "#         params = 10**np.array(res.x)[param_dict[construct]]\n",
    "        \n",
    "        noise_params = np.array(res.x)[param_dict[construct][0:1]]\n",
    "        model_params = 10**np.array(res.x)[param_dict[construct][1:]]\n",
    "    \n",
    "        amp = pp.PushAmp()\n",
    "        SpT_GFP_predict = amp.predict_all(df_data[['WT_GFP', 'ST_GFP']].values, model_params)\n",
    "#         SpT_GFP_predict = amp.predict_all(np.asfortranarray(np.c_[np.zeros(len(df_data.index)), \n",
    "#                                                 df_data['ST_GFP'].values]), params)\n",
    "        \n",
    "    elif model == 'background':\n",
    "        \n",
    "        SpT_GFP_predict = np.zeros(len(df_data.index))\n",
    "        \n",
    "    df.loc[df_data.index, 'SpT_GFP_predict'] = SpT_GFP_predict\n",
    "    \n",
    "    \n",
    "df['SpT_anti_predict'] = phospho_noise.GFP_to_anti(df['SpT_GFP_predict'])\n",
    "\n",
    "df['phospho_frac_GFP_predict'] = df['SpT_GFP_predict'] / df['ST_GFP']\n",
    "df['phospho_frac_anti_predict'] = df['SpT_anti_predict'] / df['ST_anti']\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(len(df_info.index), 1, figsize=(4, 4*len(df_info.index)),\n",
    "                        sharex=True, sharey=True, squeeze=False)\n",
    "\n",
    "\n",
    "for i, row in df_info.iterrows():\n",
    "    \n",
    "    dataset = row['dataset']\n",
    "    model = row['model']\n",
    "    construct = row['construct']\n",
    "    \n",
    "    df_data = df_data = df.query(\"dataset=='{}'\".format(dataset))\n",
    "    \n",
    "    sns.histplot(df_data, x='WT_GFP', y='phospho_frac_GFP_predict', \n",
    "                 log_scale=(True, False), ax=axes[i, 0], bins=32)\n",
    "    \n",
    "    axes[i, 0].set_ylabel(\"phospho_frac_GFP_predict\", fontsize='small')\n",
    "    \n",
    "    axes[i, 0].set_title(\"{0:} {1:}\".format(dataset, \"theoretical GFP\"), fontsize='small')\n",
    "    axes[i, 0].set_ylim(0, 1.0)\n",
    "    \n",
    "    \n",
    "    if model == 'push':\n",
    "        params = 10**np.array(res.x)[param_dict[construct][1:]]\n",
    "        \n",
    "        ST_GFP_mean = df_data['ST_GFP'].mean()\n",
    "        WT_GFP = np.logspace(0, 6, base=10)\n",
    "        \n",
    "        amp = pp.PushAmp()\n",
    "        SpT_GFP = amp.predict_all(np.asfortranarray(np.c_[WT_GFP, ST_GFP_mean*np.ones_like(WT_GFP)]), params)\n",
    "        \n",
    "       \n",
    "        axes[i, 0].plot(WT_GFP, SpT_GFP/ST_GFP_mean, 'k--')\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(len(df_info.index), 2, figsize=(8, 4*len(df_info.index)),\n",
    "                        sharex=True, sharey=True, squeeze=False)\n",
    "\n",
    "for i, row in df_info.iterrows():\n",
    "    \n",
    "    dataset = row['dataset']\n",
    "    model = row['model']\n",
    "    construct = row['construct']\n",
    "    \n",
    "    df_data = df.query(\"dataset=='{}'\".format(dataset))\n",
    "    \n",
    "    sns.histplot(df_data, x='WT_anti', y='phospho_frac_anti', \n",
    "                 log_scale=(True, True), ax=axes[i, 0])\n",
    "    sns.histplot(df_data, x='WT_anti', y='phospho_frac_anti_predict', \n",
    "                 log_scale=(True, True), ax=axes[i, 1])\n",
    "    \n",
    "    axes[i, 0].hlines(1e0, xmin=1e0, xmax=1e5, color='k', linestyle='--')\n",
    "    axes[i, 1].hlines(1e0, xmin=1e0, xmax=1e5, color='k', linestyle='--')\n",
    "    axes[i, 0].set_title(\"{0:} {1:}\".format(dataset, \"exp\"))\n",
    "    axes[i, 1].set_title(\"{0:} {1:}\".format(dataset, \"theory\"))\n",
    "    \n",
    "    axes[i, 0].set_ylim(1e-3, 1e2)\n",
    "    axes[i, 1].set_ylim(1e-3, 1e2)\n",
    "        \n",
    "    if model == 'push':\n",
    "#         params = 10**np.array(res.x)[param_dict[construct]]\n",
    "        noise_params = np.array(res.x)[param_dict[construct][0:1]]\n",
    "        model_params = 10**np.array(res.x)[param_dict[construct][1:]]\n",
    "        \n",
    "        ST_GFP_mean = df_data['ST_GFP'].mean()\n",
    "        WT_GFP = np.logspace(0, 6, base=10)\n",
    "        \n",
    "        amp = pp.PushAmp()\n",
    "        SpT_GFP = amp.predict_all(np.asfortranarray(np.c_[WT_GFP, ST_GFP_mean*np.ones_like(WT_GFP)]), model_params)\n",
    "\n",
    "        WT_anti = writer_noise.GFP_to_anti_max(WT_GFP)        \n",
    "        ST_anti = substrate_noise.GFP_to_anti_max(ST_GFP_mean*np.ones_like(WT_GFP))\n",
    "        SpT_anti = phospho_noise.GFP_to_anti_max(SpT_GFP)\n",
    "        \n",
    "        axes[i, 0].plot(WT_anti, SpT_anti/ST_anti, 'k-')\n",
    "        axes[i, 1].plot(WT_anti, SpT_anti/ST_anti, 'k-')\n",
    "\n",
    "    \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
