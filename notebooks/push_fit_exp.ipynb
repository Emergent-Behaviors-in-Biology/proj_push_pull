{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '../py_scripts')\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import numpy.random as rand\n",
    "import numpy.linalg as la\n",
    "import numpy.ma as ma\n",
    "import scipy.optimize as opt\n",
    "import scipy.stats as stats\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "\n",
    "import push_pull as pp\n",
    "# import noise_models as noise\n",
    "\n",
    "sns.set(context='talk', font_scale=1.0, color_codes=True, palette='deep', style='ticks', \n",
    "        rc={'mathtext.fontset': 'cm', 'xtick.direction': 'in','ytick.direction': 'in',\n",
    "            'axes.linewidth': 1.5, 'figure.dpi':100, 'text.usetex':False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/old/push/u5.csv\")\n",
    "\n",
    "display(df)\n",
    "\n",
    "df = df[(df[df.columns] > 0.0).all(axis=1)]\n",
    "\n",
    "data = pp.PushDataSet(df['Kinase'].values, \n",
    "                      df['Substrate'].values, \n",
    "                      df['Phosphorylation'].values)\n",
    "\n",
    "\n",
    "\n",
    "model = pp.PushAmp()\n",
    "\n",
    "params = np.array([1.0, 2.0, 3.0])\n",
    "print(model.predict(data[0], params))\n",
    "\n",
    "df_noise = pd.read_csv(\"../data/old/Kinase Noise.csv\")\n",
    "df_noise = df_noise[(df_noise[df_noise.columns] > 0.0).all(axis=1)]\n",
    "\n",
    "display(df_noise)\n",
    "\n",
    "noise = pp.EmpiricalNoise(df_noise['Flag Antibody'].values, \n",
    "                          df_noise['GFP - Area'].values, 100, 100)\n",
    "\n",
    "GFP = noise.anti_to_GFP(df['Kinase'].values, np.array([]), 42)\n",
    "\n",
    "sns.histplot(x=GFP, y=df['Kinase'].values, log_scale=(True, True), bins=(100, 100), cbar=True)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# loss_func = pp.EmpiricalPlusEmpty()\n",
    "\n",
    "# print(loss_func.loss(params, np.array([1.0, 1.0]), model, data))\n",
    "\n",
    "# sns.heatmap(hist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict = {'I+E': ('push', 'I+E'),\n",
    "              'S+E': ('push', 'S+E'),\n",
    "              'S+R': ('push', 'S+R'), \n",
    "              'RR(E) only': ('push', 'RR(E) only'), \n",
    "              'RR+A': ('push', 'RR+A')}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df_list = []\n",
    "# df = pd.read_csv(\"../data/push_data/I+E.csv\", index_col=0)\n",
    "# df['construct'] = 'I+E'\n",
    "# df_list.append(df)\n",
    "# df = pd.read_csv(\"../data/push_data/S+E.csv\", index_col=0)\n",
    "# df['construct'] = 'S+E'\n",
    "# df_list.append(df)\n",
    "df = pd.read_csv(\"../data/push_data/S+R.csv\", index_col=0)\n",
    "df['construct'] = 'S+R'\n",
    "df_list.append(df)\n",
    "# df = pd.read_csv(\"../data/push_data/RR(E) only.csv\", index_col=0)\n",
    "# df['construct'] = 'RR(E) only'\n",
    "# df_list.append(df)\n",
    "# df = pd.read_csv(\"../data/push_data/RR+A.csv\")\n",
    "# df['construct'] = 'RR+A'\n",
    "# df_list.append(df)\n",
    "\n",
    "\n",
    "df = pd.concat(df_list)\n",
    "\n",
    "\n",
    "df = df[(df[df.columns[:-1]] >= 0).all(axis=1)].rename(columns={'Kinase': 'WT_anti', 'Substrate': 'ST_anti', 'Phosphorylation': 'SpT_anti'})\n",
    "\n",
    "\n",
    "df = df.sample(frac=1.0, replace=False, random_state=776)\n",
    "\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "df['phospho_frac_anti'] = df['SpT_anti'] / df['ST_anti']\n",
    "\n",
    "\n",
    "print(len(df.index), \"/\", len(df.index))\n",
    "\n",
    "display(df)\n",
    "\n",
    "\n",
    "nconstructs = df.groupby(\"construct\").ngroups\n",
    "fig, axes = plt.subplots(nconstructs, 1, figsize=(4, 4*nconstructs),\n",
    "                        sharex=True, sharey=True, squeeze=False)\n",
    "\n",
    "print(axes)\n",
    "\n",
    "for i, (construct, group) in enumerate(df.groupby(\"construct\")):\n",
    "    \n",
    "    sns.histplot(group, x='WT_anti', y='phospho_frac_anti', \n",
    "                 log_scale=(True, True), ax=axes[i, 0])\n",
    "    \n",
    "    axes[i, 0].hlines(1e0, xmin=1e0, xmax=1e5, color='k', linestyle='--')\n",
    "    axes[i, 0].set_title(construct)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resample from Noise Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbins_anti = 200\n",
    "nbins_gfp = 200\n",
    "\n",
    "df_writer_noise = pd.read_csv(\"../data/noise_data/Kinase Noise.csv\")\n",
    "df_writer_noise = df_writer_noise[(df_writer_noise[df_writer_noise.columns] > 0.0).all(axis=1)]\n",
    "\n",
    "display(df_writer_noise)\n",
    "\n",
    "writer_noise = pp.EmpiricalNoise(df_writer_noise['Flag Antibody'].values, \n",
    "                                 df_writer_noise['GFP'].values, nbins_anti, nbins_gfp)\n",
    "\n",
    "sns.histplot(df_writer_noise, x='GFP', y='Flag Antibody', log_scale=(True, True), \n",
    "             bins=(nbins_anti, nbins_gfp), cbar=True)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "df_substrate_noise = pd.read_csv(\"../data/noise_data/Substrate Noise.csv\")\n",
    "df_substrate_noise = df_substrate_noise[(df_substrate_noise[df_substrate_noise.columns] > 0.0).all(axis=1)]\n",
    "\n",
    "display(df_substrate_noise)\n",
    "\n",
    "substrate_noise = pp.EmpiricalNoise(df_substrate_noise['Myc Antibody'].values, \n",
    "                                 df_substrate_noise['GFP'].values, nbins_anti, nbins_gfp)\n",
    "\n",
    "sns.histplot(df_substrate_noise, x='GFP', y='Myc Antibody', log_scale=(True, True), \n",
    "             bins=(nbins_anti, nbins_gfp), cbar=True)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for construct, group in df.groupby(\"construct\"):\n",
    "                    \n",
    "    df.loc[group.index, 'WT_GFP'] = writer_noise.anti_to_GFP(group['WT_anti'].values, np.array([]), 42)\n",
    "    df.loc[group.index, 'ST_GFP'] = substrate_noise.anti_to_GFP(group['ST_anti'].values, np.array([]), 42)\n",
    "    \n",
    "print(len(df))\n",
    "df = df[(df['WT_GFP']!=-1) & (df['ST_GFP']!=-1)].reset_index(drop=True)\n",
    "print(len(df))\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve(datasets, noise_model, model_dict, param_dict, x0, bounds, verbose=False):\n",
    "\n",
    "    if verbose:\n",
    "        start = time.time()\n",
    "\n",
    "    def func(x, args):\n",
    "        \n",
    "#         print(x)\n",
    "                \n",
    "        datasets, noise_model = args\n",
    "\n",
    "        loss = 0.0\n",
    "        norm = 0.0\n",
    "        for construct in datasets:\n",
    "            \n",
    "            (model_type, model_id) = model_dict[construct]\n",
    "            dataset = datasets[construct]\n",
    "            \n",
    "            N_data = dataset.size()\n",
    "            \n",
    "            norm += N_data\n",
    "                        \n",
    "            if model_type == 'push':\n",
    "                \n",
    "                noise_params = np.array(x)[param_dict[model_id][0]]\n",
    "                model_params = 10**np.array(x)[param_dict[model_id][1]]\n",
    "                \n",
    "                model = pp.PushAmp()\n",
    "                \n",
    "#                 print(model_params, noise_params)\n",
    "                \n",
    "                loss += N_data * noise_model.loss(dataset, model_params, noise_params, model)                \n",
    "                \n",
    "            elif model_type == 'background':\n",
    "                \n",
    "#                 Sigma2, A, logvbgp = np.array(x)[param_dict[model_id]]\n",
    "                \n",
    "#                 loss += N_data * model.loss(\n",
    "#                     np.array([10**logvbgp]), \n",
    "#                     np.array([Sigma2, A, 0.0]))\n",
    "                pass\n",
    "        \n",
    "        loss /= norm\n",
    "        \n",
    "#         print(loss, x)\n",
    "        \n",
    "        return loss\n",
    "\n",
    "\n",
    "    if verbose:\n",
    "        print(\"Initial Loss:\", func(x0, (datasets, noise_model)))\n",
    "\n",
    "\n",
    "    res = opt.minimize(func, x0, args=((datasets, noise_model),), method='L-BFGS-B', \n",
    "                       jac='2-point', bounds=bounds, \n",
    "                       options={'iprint':101, 'eps': 1e-8, \n",
    "                                'gtol': 1e-8, 'ftol':1e-12,\n",
    "                               'finite_diff_rel_step': 1e-4})\n",
    "    \n",
    "\n",
    "    if verbose:\n",
    "        print(\"Final Loss:\", res.fun)\n",
    "\n",
    "        end = time.time()\n",
    "\n",
    "        print(\"Time Elapsed\", end-start, \"seconds\")\n",
    "\n",
    "        print(res)\n",
    "        \n",
    "    \n",
    "    return res\n",
    "\n",
    "\n",
    "df_phospho_noise = pd.read_csv(\"../data/noise_data/PE Noise.csv\")\n",
    "df_phospho_noise = df_phospho_noise[(df_phospho_noise[df_phospho_noise.columns] > 0.0).all(axis=1)]\n",
    "\n",
    "display(df_phospho_noise)\n",
    "\n",
    "phospho_noise = pp.EmpiricalNoise(df_phospho_noise['PE Antibody'].values, \n",
    "                                 df_phospho_noise['GFP'].values, nbins_anti, nbins_gfp)\n",
    "\n",
    "sns.histplot(df_phospho_noise, x='GFP', y='PE Antibody', log_scale=(True, True), \n",
    "             bins=(nbins_anti, nbins_gfp), cbar=True)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only need one model of each type, so this can be recajiggered\n",
    "# Next step: see what results look like to see if even in the right regime for fit params, confused why not\n",
    "# is discreteness of optimization function creating issues?\n",
    "# plot average antibody curve\n",
    "\n",
    "\n",
    "param_dict = {}\n",
    "datasets = {}\n",
    "\n",
    "n_push = 0\n",
    "\n",
    "param_labels = [r\"$\\rho$\", r\"$\\log_{10}(v_{bg}^p)$\", r\"$\\log_{10}(v_{WS}^p)$\"]\n",
    "\n",
    "for construct, group in df.groupby(\"construct\"):\n",
    "    \n",
    "    (model_type, model_id) = model_dict[construct]\n",
    "            \n",
    "    if model_id not in param_dict:\n",
    "        if model_type == 'background':\n",
    "            param_dict[model_id] = ([0], [1])\n",
    "        elif model_type == 'push':\n",
    "            param_dict[model_id] = ([0], [1, 2, 3+n_push])\n",
    "            n_push += 1\n",
    "            \n",
    "            param_labels.append(model_id + \": \" + r\"$\\log_{10}(\\alpha_{WS})$\")\n",
    "        \n",
    "    \n",
    "    if model_type == 'background':\n",
    "#         model = ppamp.Background()\n",
    "#         model.set_data(group['ST_GFP'].values.copy(), \n",
    "#                        group['SpT_anti'].values.copy())\n",
    "        pass\n",
    "    elif model_type == 'push':\n",
    "        data = pp.PushDataSet(group['WT_GFP'].values, \n",
    "                      group['ST_GFP'].values, \n",
    "                      group['SpT_anti'].values)\n",
    "      \n",
    "    datasets[construct] = data\n",
    "        \n",
    "\n",
    "print(param_labels)\n",
    "print(param_dict)\n",
    "print(datasets)\n",
    "\n",
    "x0 = [0.0, 0.0, 1.0] + n_push * [2.0]\n",
    "bounds = [(0.0, 1.0), (None, None), (None, None)] + n_push * [(None, None)]\n",
    "\n",
    "res = solve(datasets, phospho_noise, model_dict, param_dict, x0, bounds, verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict = {'kinase_dead': ('background', 'background'),\n",
    "              'sub_only': ('push', 'EE(L)*'),\n",
    "              'u005': ('push', 'EE(L)*'), \n",
    "              'u030': ('push', 'EE(L)*'), \n",
    "              'u060': ('push', 'EE(L)*'),\n",
    "              'u100': ('push', 'EE(L)*'),\n",
    "              'EE(I)': ('push', 'EE(I)'), \n",
    "              'EE(L)': ('push', 'EE(L)'), \n",
    "              'EE(S)': ('push', 'EE(S)'), \n",
    "              'EE(E)': ('push', 'EE(E)'),\n",
    "              'RR': ('push', 'RR')}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df_list = []\n",
    "df = pd.read_csv(\"../data/push/u5.csv\")\n",
    "df['dataset'] = 'u005'\n",
    "df_list.append(df)\n",
    "df = pd.read_csv(\"../data/push/u30.csv\")\n",
    "df['dataset'] = 'u030'\n",
    "df_list.append(df)\n",
    "df = pd.read_csv(\"../data/push/u60.csv\")\n",
    "df['dataset'] = 'u060'\n",
    "df_list.append(df)\n",
    "df = pd.read_csv(\"../data/push/u100.csv\")\n",
    "df['dataset'] = 'u100'\n",
    "df_list.append(df)\n",
    "df = pd.read_csv(\"../data/push/Substrate only.csv\")\n",
    "df['dataset'] = 'sub_only'\n",
    "df_list.append(df)\n",
    "df = pd.read_csv(\"../data/push/Kinase Dead.csv\")\n",
    "df['dataset'] = 'kinase_dead'\n",
    "df_list.append(df)\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"../data/push/EE(I).csv\")\n",
    "df['dataset'] = 'EE(I)'\n",
    "df_list.append(df)\n",
    "df = pd.read_csv(\"../data/push/EE(L).csv\")\n",
    "df['dataset'] = 'EE(L)'\n",
    "df_list.append(df)\n",
    "df = pd.read_csv(\"../data/push/EE(S).csv\")\n",
    "df['dataset'] = 'EE(S)'\n",
    "df_list.append(df)\n",
    "df = pd.read_csv(\"../data/push/EE(E).csv\")\n",
    "df['dataset'] = 'EE(E)'\n",
    "df_list.append(df)\n",
    "df = pd.read_csv(\"../data/push/RR.csv\")\n",
    "df['dataset'] = 'RR'\n",
    "df_list.append(df)\n",
    "\n",
    "\n",
    "df = pd.concat(df_list)\n",
    "\n",
    "\n",
    "df = df[(df[df.columns[:-1]] >= 0).all(axis=1)].rename(columns={'Kinase': 'WT_anti', 'Substrate': 'ST_anti', 'Phosphorylation': 'SpT_anti'})\n",
    "\n",
    "\n",
    "df = df.sample(frac=1.0, replace=False, random_state=776)\n",
    "\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "df['SpT_anti/ST_anti'] = df['SpT_anti'] / df['ST_anti']\n",
    "\n",
    "\n",
    "print(len(df.index), \"/\", len(df.index))\n",
    "\n",
    "display(df)\n",
    "\n",
    "\n",
    "ndatasets = df.groupby(\"dataset\").ngroups\n",
    "fig, axes = plt.subplots(ndatasets, 1, figsize=(4, 4*ndatasets),\n",
    "                        sharex=True, sharey=True)\n",
    "\n",
    "for i, (dataset, group) in enumerate(df.groupby(\"dataset\")):\n",
    "    \n",
    "    sns.histplot(group, x='WT_anti', y='SpT_anti/ST_anti', \n",
    "                 log_scale=(True, True), ax=axes[i])\n",
    "    \n",
    "    axes[i].hlines(1e0, xmin=1e0, xmax=1e5, color='k', linestyle='--')\n",
    "    axes[i].set_title(dataset)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbins_anti = 100\n",
    "nbins_gfp = 100\n",
    "\n",
    "writer_noise = noise.EmpNoiseModel(\"../data/Kinase Noise.csv\", \n",
    "                                   'Flag Antibody', 'GFP - Area', \n",
    "                                   nbins_anti=nbins_anti, nbins_gfp=nbins_gfp, \n",
    "                                   verbose=True)\n",
    "writer_noise.plot()\n",
    "\n",
    "for dataset, group in df.groupby(\"dataset\"):\n",
    "    \n",
    "    print(dataset)\n",
    "    \n",
    "    df.loc[group.index, 'WT_GFP'] = writer_noise.anti_to_GFP(group['WT_anti'], \n",
    "                                                             plot=False)\n",
    "    \n",
    "    \n",
    "substrate_noise = noise.EmpNoiseModel(\"../data/Substrate Noise.csv\", \n",
    "                                   'Myc Antibody', 'GFP - Area', \n",
    "                                   nbins_anti=nbins_anti, nbins_gfp=nbins_gfp, \n",
    "                                   verbose=True)\n",
    "substrate_noise.plot()\n",
    "\n",
    "for dataset, group in df.groupby(\"dataset\"):\n",
    "    \n",
    "    print(dataset)\n",
    "    \n",
    "    df.loc[group.index, 'ST_GFP'] = substrate_noise.anti_to_GFP(group['ST_anti'], \n",
    "                                                                plot=False)\n",
    "\n",
    "\n",
    "\n",
    "print(len(df))\n",
    "df.dropna(inplace=True)\n",
    "print(len(df))\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve(models, model_dict, param_dict, x0, bounds, verbose=False):\n",
    "\n",
    "    if verbose:\n",
    "        start = time.time()\n",
    "\n",
    "    def loss(x, args):\n",
    "        \n",
    "\n",
    "        Sigma2 = x[0]\n",
    "        A = x[1]\n",
    "        logvbgp = x[2]\n",
    "        logvWSp = x[3]\n",
    "        \n",
    "\n",
    "        (models) = args\n",
    "\n",
    "        loss = 0.0\n",
    "        norm = 0.0\n",
    "        for dataset in models:\n",
    "            \n",
    "            (model_type, model_id) = model_dict[dataset]\n",
    "            model = models[dataset]\n",
    "            \n",
    "            N_data = model.N_data\n",
    "            \n",
    "            norm += N_data\n",
    "                        \n",
    "            if model_type == 'push':\n",
    "                  \n",
    "                Sigma2, A, logvbgp, logvWSp, logalphaWS = np.array(x)[param_dict[model_id]]\n",
    "\n",
    "                loss += N_data * model.loss(\n",
    "                    np.array([10**logalphaWS, 10**logvWSp, 10**logvbgp]), \n",
    "                    np.array([Sigma2, A, 0.0]))\n",
    "            elif model_type == 'background':\n",
    "                \n",
    "                Sigma2, A, logvbgp = np.array(x)[param_dict[model_id]]\n",
    "                \n",
    "                loss += N_data * model.loss(\n",
    "                    np.array([10**logvbgp]), \n",
    "                    np.array([Sigma2, A, 0.0]))\n",
    "        \n",
    "        loss /= norm\n",
    "        \n",
    "        return loss\n",
    "\n",
    "\n",
    "    if verbose:\n",
    "        print(\"Initial Loss:\", loss(x0, (models)))\n",
    "\n",
    "\n",
    "    res = opt.minimize(loss, x0, args=(models,), method='L-BFGS-B', \n",
    "                       jac='2-point', bounds=bounds, \n",
    "                       options={'iprint':101, 'eps': 1e-8, \n",
    "                                'gtol': 1e-8, 'ftol':1e-12})\n",
    "    \n",
    "\n",
    "    if verbose:\n",
    "        print(\"Final Loss:\", res.fun)\n",
    "\n",
    "        end = time.time()\n",
    "\n",
    "        print(\"Time Elapsed\", end-start, \"seconds\")\n",
    "\n",
    "        print(res)\n",
    "        \n",
    "    \n",
    "    return res\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {}\n",
    "param_dict = {}\n",
    "\n",
    "n_push = 0\n",
    "\n",
    "param_labels = [r\"$\\Sigma^2$\", r\"$A$\", r\"$\\log_{10}(v_{bg}^p)$\", r\"$\\log_{10}(v_{WS}^p)$\"]\n",
    "\n",
    "for dataset, group in df.groupby(\"dataset\"):\n",
    "    \n",
    "    (model_type, model_id) = model_dict[dataset]\n",
    "            \n",
    "    if model_id not in param_dict:\n",
    "        if model_type == 'background':\n",
    "            param_dict[model_id] = [0, 1, 2]\n",
    "        elif model_type == 'push':\n",
    "            param_dict[model_id] = [0, 1, 2, 3, 4+n_push]\n",
    "            n_push += 1\n",
    "            \n",
    "            param_labels.append(model_id + \": \" + r\"$\\log_{10}(\\alpha_{WS})$\")\n",
    "        \n",
    "    \n",
    "    if model_type == 'background':\n",
    "        model = ppamp.Background()\n",
    "        model.set_data(group['ST_GFP'].values.copy(), \n",
    "                       group['SpT_anti'].values.copy())\n",
    "\n",
    "    elif model_type == 'push':\n",
    "        model = ppamp.Push()\n",
    "        model.set_data(group['WT_GFP'].values.copy(),\n",
    "                       group['ST_GFP'].values.copy(), \n",
    "                       group['SpT_anti'].values.copy())\n",
    "                \n",
    "    models[dataset] = model\n",
    "\n",
    "print(param_dict)\n",
    "\n",
    "x0 = [0.05, 1.0, 0.0, 1.0] + n_push * [3.0]\n",
    "bounds = [(1e-2, None), (1e-2, None), (None, None), (None, None)] + n_push * [(None, None)]\n",
    "\n",
    "res = solve(models, model_dict, param_dict, x0, bounds, verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hess = la.inv(res.hess_inv.todense())\n",
    "\n",
    "print(\"Noise parameters\")\n",
    "for i in range(2):\n",
    "    display(Markdown(param_labels[i] + \" = \" + str(res.x[i])))\n",
    "\n",
    "print(\"Model parameters:\")\n",
    "for i in range(2, len(res.x)):\n",
    "    display(Markdown(param_labels[i] + \" = \" + str(res.x[i])))\n",
    "    \n",
    "\n",
    "s_list = []\n",
    "\n",
    "for i, labeli in enumerate(param_labels):\n",
    "    for j, labelj in enumerate(param_labels):\n",
    "        s_list.append([labeli, labelj, np.log10(np.abs(hess[i, j]))])\n",
    "\n",
    "df_hess = pd.DataFrame(s_list, columns=['param1', 'param2', 'hess'])\n",
    "sns.heatmap(df_hess.pivot(\"param1\", \"param2\", \"hess\"), \n",
    "            cbar_kws={'label': r\"$\\log_{10}(|H_{ij}|)$\"}, \n",
    "            cmap='cividis', center=0)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "evals, evecs = la.eigh(hess)\n",
    "\n",
    "evals = evals[::-1]\n",
    "evecs = evecs[:, ::-1]\n",
    "\n",
    "s_list = []\n",
    "for i, labeli in enumerate(param_labels):\n",
    "    for j in range(len(evals)):\n",
    "        s_list.append([labeli, \"{:07.4f}\".format(evals[j]), np.abs(evecs[i, j])])\n",
    "\n",
    "df_evecs = pd.DataFrame(s_list, columns=['param', \"PC (eigenval)\", 'val'])\n",
    "sns.heatmap(df_evecs.pivot(\"PC (eigenval)\", \"param\", \"val\"), \n",
    "            cbar_kws={'label': \"weight\"}, \n",
    "            cmap='RdBu', center=0)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hess_inv = res.hess_inv.todense()\n",
    "\n",
    "zippers = {}\n",
    "\n",
    "\n",
    "for dataset in model_dict:\n",
    "    \n",
    "    (model_type, model_id) = model_dict[dataset]\n",
    "    \n",
    "    if model_id not in param_dict:\n",
    "        continue\n",
    "\n",
    "    if model_type == 'push':\n",
    "        \n",
    "        if model_id not in zippers:\n",
    "            idx = param_dict[model_id][4]\n",
    "            zippers[model_id] = (res.x[idx], 0.01*np.sqrt(hess_inv[idx, idx]))\n",
    "\n",
    "\n",
    "print(zippers)\n",
    "            \n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 6))\n",
    "\n",
    "y = 10**np.array([zippers[key][0] for key in zippers])\n",
    "y_low =  y - 10**np.array([zippers[key][0]-zippers[key][1] for key in zippers])\n",
    "y_up =  10**np.array([zippers[key][0]+zippers[key][1] for key in zippers]) - y\n",
    "\n",
    "ax.bar(zippers.keys(), y, yerr=(y_low, y_up))\n",
    "\n",
    "ax.set_yscale('log')\n",
    "ax.set_xlabel(\"Zipper\")\n",
    "ax.set_ylabel(\"Inverse Binding Strength\\n\" + r\"$\\alpha_{WS} = k^{off}/k^{on}$ [GFP]\")\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for dataset in models:\n",
    "    model = models[dataset]\n",
    "    (model_type, model_id) = model_dict[dataset]\n",
    "    \n",
    "    if isinstance(model, ppamp.Push):\n",
    "        Sigma2, A, logvbgp, logvWSp, logalphaWS = np.array(res.x)[param_dict[model_id]]\n",
    "        \n",
    "        SpT_GFP_predict = model.predict_all(\n",
    "            np.array([10**logalphaWS, 10**logvWSp, 10**logvbgp]))\n",
    "    elif isinstance(model, ppamp.Background):\n",
    "        Sigma2, A, logvbgp = np.array(res.x)[param_dict[model_id]]\n",
    "        \n",
    "        SpT_GFP_predict = model.predict_all(\n",
    "            np.array([10**logvbgp]))\n",
    "        \n",
    "    df.loc[df[df.dataset==dataset].index, 'SpT_GFP_predict'] = SpT_GFP_predict\n",
    "    \n",
    "    \n",
    "ST_noise = noise.LogNormNoiseModel(Sigma2=Sigma2, A=A, B=0.0)\n",
    "\n",
    "df['SpT_anti_predict'] = ST_noise.GFP_to_anti(df['SpT_GFP_predict'])\n",
    "\n",
    "df['SpT_GFP_predict/ST_GFP'] = df['SpT_GFP_predict'] / df['ST_GFP']\n",
    "df['SpT_anti_predict/ST_anti'] = df['SpT_anti_predict'] / df['ST_anti']\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndatasets = df.groupby(\"dataset\").ngroups\n",
    "fig, axes = plt.subplots(ndatasets, 2, figsize=(8, 4*ndatasets),\n",
    "                        sharex=True, sharey=True)\n",
    "\n",
    "for i, (dataset, group) in enumerate(df.groupby(\"dataset\")):\n",
    "    \n",
    "    sns.histplot(group, x='WT_anti', y='SpT_anti/ST_anti', \n",
    "                 log_scale=(True, True), ax=axes[i, 0])\n",
    "    sns.histplot(group, x='WT_anti', y='SpT_anti_predict/ST_anti', \n",
    "                 log_scale=(True, True), ax=axes[i, 1])\n",
    "    \n",
    "    axes[i, 0].hlines(1e0, xmin=1e0, xmax=1e5, color='k', linestyle='--')\n",
    "    axes[i, 1].hlines(1e0, xmin=1e0, xmax=1e5, color='k', linestyle='--')\n",
    "    axes[i, 0].set_title(\"{0:} {1:}\".format(dataset, \"exp\"))\n",
    "    axes[i, 1].set_title(\"{0:} {1:}\".format(dataset, \"theory\"))\n",
    "    \n",
    "    model = models[dataset]\n",
    "    \n",
    "    \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndatasets = df.groupby(\"dataset\").ngroups\n",
    "fig, axes = plt.subplots(ndatasets, 1, figsize=(4, 4*ndatasets),\n",
    "                        sharex=True, sharey=True)\n",
    "\n",
    "for i, (dataset, group) in enumerate(df.groupby(\"dataset\")):\n",
    "    \n",
    "    sns.histplot(group, x='WT_GFP', y='SpT_GFP_predict/ST_GFP', \n",
    "                 log_scale=(True, False), ax=axes[i], bins=32)\n",
    "    \n",
    "    axes[i].set_title(\"{0:} {1:}\".format(dataset, \"theoretical GFP\"))\n",
    "#     axes[i].set_ylim(0, 1)\n",
    "\n",
    "\n",
    "#     ST_list = [1e0, 1e2, 1e4, 1e6]\n",
    "\n",
    " \n",
    "#     palette = iter(sns.color_palette(\"Reds\", len(ST_list)))\n",
    "#     for ST in ST_list:\n",
    "#         WT = np.logspace(0.0, 5.0, 100)\n",
    "        \n",
    "#         if dataset == 'kinase_dead':\n",
    "            \n",
    "#             model.set_data(ST*np.ones_like(WT), np.array([]))\n",
    "#             SpT_predict = model.predict_all(\n",
    "#                 np.array([10**logvbgp]))\n",
    "            \n",
    "#             color = next(palette)\n",
    "#             axes[i, 0].plot(WT, SpT_predict/ST, '-', \n",
    "#                             color=color, lw=1.5)\n",
    "#             axes[i, 1].plot(WT, SpT_predict/ST, '-', \n",
    "#                             color=color, lw=1.5)\n",
    "            \n",
    "#         else:\n",
    "#             model.set_data(WT, ST*np.ones_like(WT), np.array([]))\n",
    "#             SpT_predict = model.predict_all(\n",
    "#                 np.array([10**logalphaWS, 10**logvWSp, 10**logvbgp]))\n",
    "            \n",
    "#             color = next(palette)\n",
    "#             axes[i, 0].plot(WT, SpT_predict/ST, '-', \n",
    "#                             color=color, lw=1.5)\n",
    "#             axes[i, 1].plot(WT, SpT_predict/ST, '-', \n",
    "#                             color=color, lw=1.5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndatasets = df.groupby(\"dataset\").ngroups\n",
    "fig, axes = plt.subplots(ndatasets, 2, figsize=(8, 4*ndatasets),\n",
    "                        sharex=True, sharey=True)\n",
    "\n",
    "for i, (dataset, group) in enumerate(df.groupby(\"dataset\")):\n",
    "    \n",
    "    sns.histplot(group, x='SpT_anti', \n",
    "                 log_scale=True, ax=axes[i, 0], label=\"exp\", bins=64,\n",
    "                 element=\"step\", fill=False, stat='density')\n",
    "    sns.histplot(group, x='SpT_anti_predict', \n",
    "                 log_scale=True, ax=axes[i, 0], label=\"theory\", color='g', bins=64,\n",
    "                 element=\"step\", fill=False, stat='density')\n",
    "    \n",
    "    axes[i, 0].set_title(dataset)\n",
    "    axes[i, 0].legend()\n",
    "    \n",
    "    sns.histplot(group, x='SpT_anti/ST_anti', \n",
    "                 log_scale=True, ax=axes[i, 1], label=\"exp\", bins=64,\n",
    "                 element=\"step\", fill=False, stat='density')\n",
    "    sns.histplot(group, x='SpT_anti_predict/ST_anti', \n",
    "                 log_scale=True, ax=axes[i, 1], label=\"theory\", color='g', bins=64,\n",
    "                 element=\"step\", fill=False, stat='density')\n",
    "    \n",
    "    axes[i, 1].set_title(dataset)\n",
    "    axes[i, 1].legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
